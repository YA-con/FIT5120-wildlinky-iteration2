{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdAhx0ta-hUs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count Threatened Species Listed Per Year"
      ],
      "metadata": {
        "id": "NYVX6DnYOwbb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "owBTD1zFStMT",
        "outputId": "d6b83a0e-bce6-480c-cf12-1e54b90d0df0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'EPBC Act List of Threatened Fauna.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-dcf3db567a35>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the threatened fauna dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mspecies_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPBC Act List of Threatened Fauna.xlsx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Sheet2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Extract the year from the 'Effective' date column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'EPBC Act List of Threatened Fauna.xlsx'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the threatened fauna dataset\n",
        "species_df = pd.read_excel(\"EPBC Act List of Threatened Fauna.xlsx\", sheet_name=\"Sheet2\")\n",
        "\n",
        "# Extract the year from the 'Effective' date column\n",
        "species_df['year'] = pd.to_datetime(species_df['Effective'], errors='coerce').dt.year\n",
        "\n",
        "# Count the number of species listed per year\n",
        "species_per_year = species_df.groupby('year').size().reset_index(name='species_count')\n",
        "\n",
        "# Display the result\n",
        "print(species_per_year.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Urban Area Data"
      ],
      "metadata": {
        "id": "48r3VqOoPA1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load urban area data\n",
        "urban_df = pd.read_csv(\"Urban_Area_Victoria_MODIS.csv\")\n",
        "\n",
        "# Keep only relevant columns\n",
        "urban_df = urban_df[['year', 'urban_area_ha']]\n",
        "\n",
        "# Merge with species_per_year\n",
        "merged_df = species_per_year.merge(urban_df, on='year', how='left')\n",
        "\n",
        "# Display result\n",
        "print(merged_df.head(10))\n"
      ],
      "metadata": {
        "id": "yd460jsOSt9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Burned Area Data"
      ],
      "metadata": {
        "id": "DVQnF9SAPszx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load burned area data\n",
        "burned_df = pd.read_csv(\"Victoria_Burned_Area_MODIS.csv\")\n",
        "\n",
        "\n",
        "# Group by year and sum the burned area\n",
        "burned_df_cleaned = (\n",
        "    burned_df.groupby('year')['burned_area_ha']\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Merge with the existing merged_df\n",
        "merged_df = merged_df.merge(burned_df_cleaned, on='year', how='left')\n",
        "\n",
        "\n",
        "# Display result\n",
        "print(merged_df.head(10))\n"
      ],
      "metadata": {
        "id": "hECLMMWNS5wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Rainfall and Temperature"
      ],
      "metadata": {
        "id": "MRf7Zb2AQ1RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load rainfall data\n",
        "rainfall_df = pd.read_excel(\"rainfall_vicxlsx.xlsx\")\n",
        "rainfall_df = rainfall_df[['Year', 'Annual']].rename(columns={'Year': 'year', 'Annual': 'rainfall_annual_mm'})\n",
        "\n",
        "# Load temperature data\n",
        "temp_df = pd.read_excel(\"temp_vic.xlsx\")\n",
        "temp_df = temp_df[['Year', 'Annual']].rename(columns={'Year': 'year', 'Annual': 'temp_annual_c'})\n",
        "\n",
        "# Merge both into the existing merged_df\n",
        "merged_df = merged_df.merge(rainfall_df, on='year', how='left')\n",
        "merged_df = merged_df.merge(temp_df, on='year', how='left')\n",
        "\n",
        "# Show updated result\n",
        "print(merged_df.head(10))\n"
      ],
      "metadata": {
        "id": "jliznAnKPvaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Population Data"
      ],
      "metadata": {
        "id": "T8m9PHhTRBGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and skip metadata rows\n",
        "pop_df = pd.read_excel(\"vic_pop.xlsx\", sheet_name=\"Data1\", skiprows=10)\n",
        "\n",
        "# Rename the columns using visual confirmation\n",
        "pop_df.columns = [\n",
        "    'quarter',\n",
        "    'pop_male_vic',\n",
        "    'pop_male_aus',\n",
        "    'pop_female_vic',\n",
        "    'pop_female_aus',\n",
        "    'pop_total_vic',\n",
        "    'pop_total_aus'\n",
        "]\n",
        "\n",
        "# Drop rows with missing total Vic population\n",
        "pop_df = pop_df[['quarter', 'pop_total_vic']].dropna()\n",
        "\n",
        "# Extract year from the 'quarter' date\n",
        "pop_df['year'] = pd.to_datetime(pop_df['quarter']).dt.year\n",
        "\n",
        "# Average quarterly estimates per year\n",
        "pop_annual = (\n",
        "    pop_df.groupby('year')['pop_total_vic']\n",
        "    .mean()\n",
        "    .round()\n",
        "    .astype(int)\n",
        "    .reset_index()\n",
        "    .rename(columns={'pop_total_vic': 'population'})\n",
        ")\n",
        "\n",
        "# Display result\n",
        "print(pop_annual.head(10))"
      ],
      "metadata": {
        "id": "YfZEoLj0Q6GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Merge"
      ],
      "metadata": {
        "id": "xk2KhxiHTgXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge cleaned population data into the main dataset\n",
        "merged_df = merged_df.merge(pop_annual, on='year', how='left')\n",
        "\n",
        "# Show the final result\n",
        "print(merged_df.head(15))"
      ],
      "metadata": {
        "id": "4sJObTApRVUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting to CSV"
      ],
      "metadata": {
        "id": "TCFsZWcbTtQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.to_csv(\"prediction_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "fcGZnqc4TH5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.read_csv(\"prediction_dataset.csv\")\n"
      ],
      "metadata": {
        "id": "_NR0TOH4cd8U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}